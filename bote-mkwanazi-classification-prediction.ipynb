{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:03.804508Z",
     "iopub.status.busy": "2021-10-08T15:32:03.803622Z",
     "iopub.status.idle": "2021-10-08T15:32:03.818091Z",
     "shell.execute_reply": "2021-10-08T15:32:03.817186Z",
     "shell.execute_reply.started": "2021-10-08T15:32:03.804449Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS \n",
    "\n",
    "<a id='table'></a>\n",
    "### 1. [Importing Libraries](#libraries)  \n",
    "\n",
    "### 2. [Loading Data](#train_and_test)  \n",
    "    \n",
    "### 3. [Cleaning Data](#cleaning)  \n",
    "     \n",
    "### 4. [Exploratory Data Analysis](#EDA)\n",
    "\n",
    "### 5. [Feature Engineering](#extraction)\n",
    "\n",
    "### 6. [Modelling](#modelling)\n",
    "\n",
    "### 7. [Model Results](#findings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries\n",
    "<a id='libraries'></a>\n",
    "   [Back to table of contents](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:03.819963Z",
     "iopub.status.busy": "2021-10-08T15:32:03.81974Z",
     "iopub.status.idle": "2021-10-08T15:32:13.457201Z",
     "shell.execute_reply": "2021-10-08T15:32:13.456477Z",
     "shell.execute_reply.started": "2021-10-08T15:32:03.819937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stopwordsiso in c:\\users\\botem\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stopwordsiso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\botem\\anaconda3\\lib\\site-packages (5.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\botem\\anaconda3\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\botem\\anaconda3\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:13.459274Z",
     "iopub.status.busy": "2021-10-08T15:32:13.459067Z",
     "iopub.status.idle": "2021-10-08T15:32:38.864915Z",
     "shell.execute_reply": "2021-10-08T15:32:38.864163Z",
     "shell.execute_reply.started": "2021-10-08T15:32:13.459246Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-054e81f3b00d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure_factory\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFreqDistVisualizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRadViz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "# Libraries used to load dataframe and visualize data\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "from yellowbrick.features import RadViz\n",
    "from wordcloud import WordCloud\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "%matplotlib inline\n",
    "\n",
    "# Noise removal helper libraries\n",
    "import re\n",
    "import string \n",
    "from stopwordsiso import stopwords as sw\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Text Preprocessing\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Feature Engineering and Data preparation for modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Model building and training\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#save the final model and vectorizer\n",
    "import pickle\n",
    "\n",
    "# width_size\n",
    "context = pd.option_context('display.max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data\n",
    "<a id='train_and_test'></a>\n",
    "   [Back to table of contents](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T17:39:10.371166Z",
     "iopub.status.busy": "2021-10-08T17:39:10.369765Z",
     "iopub.status.idle": "2021-10-08T17:39:10.56085Z",
     "shell.execute_reply": "2021-10-08T17:39:10.559878Z",
     "shell.execute_reply.started": "2021-10-08T17:39:10.371103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading train and test dataframes\n",
    "train_df = pd.read_csv('/kaggle/input/edsa-climate-change-belief-analysis-2021/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/edsa-climate-change-belief-analysis-2021/test.csv')\n",
    "train = pd.read_csv('/kaggle/input/edsa-climate-change-belief-analysis-2021/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/edsa-climate-change-belief-analysis-2021/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:39.081001Z",
     "iopub.status.busy": "2021-10-08T15:32:39.080783Z",
     "iopub.status.idle": "2021-10-08T15:32:39.103043Z",
     "shell.execute_reply": "2021-10-08T15:32:39.102282Z",
     "shell.execute_reply.started": "2021-10-08T15:32:39.080976Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the first 10 rows training dataset dataframe, allowing maximum width for the message column\n",
    "with context:\n",
    "    display(train_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:39.104539Z",
     "iopub.status.busy": "2021-10-08T15:32:39.104267Z",
     "iopub.status.idle": "2021-10-08T15:32:39.115721Z",
     "shell.execute_reply": "2021-10-08T15:32:39.114887Z",
     "shell.execute_reply.started": "2021-10-08T15:32:39.104509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the first 10 rows testing dataset dataframe, allowing maximum width for the message column\n",
    "with context:\n",
    "    display(test_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning Data\n",
    "<a id='cleaning'></a>\n",
    "   [Back to table of contents](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:39.117932Z",
     "iopub.status.busy": "2021-10-08T15:32:39.117097Z",
     "iopub.status.idle": "2021-10-08T15:32:39.126792Z",
     "shell.execute_reply": "2021-10-08T15:32:39.125894Z",
     "shell.execute_reply.started": "2021-10-08T15:32:39.117887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create function to clean data\n",
    "def clean_data(df):\n",
    "    \n",
    "    # removing noise with regex.\n",
    "    address = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)' \n",
    "    df.message.replace(to_replace = address, value = '', regex = True, inplace=True)\n",
    "    df.message.replace({r'@(\\w+)'}, value = '', regex = True, inplace=True)\n",
    "    df.message.replace({r'\\d+'}, value = '', regex = True, inplace=True)\n",
    "    df.message.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "    \n",
    "    # lower cases to avoid capital letters noise \n",
    "    lower_cases = lambda tweets: ''.join([i.lower() for i in tweets])\n",
    "    df['message'] = df.message.apply(lower_cases)\n",
    "    \n",
    "    # this function removes punctuation\n",
    "    punctuations = lambda tweets: ''.join([i for i in tweets if i not in string.punctuation])\n",
    "    df['message'] = df.message.apply(punctuations)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:39.128815Z",
     "iopub.status.busy": "2021-10-08T15:32:39.128Z",
     "iopub.status.idle": "2021-10-08T15:32:39.882206Z",
     "shell.execute_reply": "2021-10-08T15:32:39.881378Z",
     "shell.execute_reply.started": "2021-10-08T15:32:39.12878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display first 10 rows of clean data of train dataset, allowing max of width\n",
    "train_df_clean = clean_data(train_df)\n",
    "\n",
    "with context:\n",
    "    display(train_df_clean.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:39.883423Z",
     "iopub.status.busy": "2021-10-08T15:32:39.88321Z",
     "iopub.status.idle": "2021-10-08T15:32:40.383385Z",
     "shell.execute_reply": "2021-10-08T15:32:40.38257Z",
     "shell.execute_reply.started": "2021-10-08T15:32:39.883398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display first 10 rows of clean data of test dataset\n",
    "test_df_clean = clean_data(test_df)\n",
    "\n",
    "with context:\n",
    "    display(test_df_clean.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:40.384843Z",
     "iopub.status.busy": "2021-10-08T15:32:40.384425Z",
     "iopub.status.idle": "2021-10-08T15:32:40.390114Z",
     "shell.execute_reply": "2021-10-08T15:32:40.389277Z",
     "shell.execute_reply.started": "2021-10-08T15:32:40.3848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create function that tokenizes the words in a dataframe\n",
    "def tokenize(df, column):\n",
    "    df = df.copy()\n",
    "    df[column] = df[column].apply(TweetTokenizer(reduce_len = True).tokenize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:40.393071Z",
     "iopub.status.busy": "2021-10-08T15:32:40.392848Z",
     "iopub.status.idle": "2021-10-08T15:32:42.425465Z",
     "shell.execute_reply": "2021-10-08T15:32:42.424669Z",
     "shell.execute_reply.started": "2021-10-08T15:32:40.393028Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a tokenized training dataframe\n",
    "train_df_tokens = tokenize(train_df_clean, 'message')\n",
    "\n",
    "with context:\n",
    "    display(train_df_tokens.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:42.42701Z",
     "iopub.status.busy": "2021-10-08T15:32:42.426802Z",
     "iopub.status.idle": "2021-10-08T15:32:43.791441Z",
     "shell.execute_reply": "2021-10-08T15:32:43.790853Z",
     "shell.execute_reply.started": "2021-10-08T15:32:42.426985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a tokenized testing dataframe\n",
    "test_df_tokens = tokenize(test_df_clean, 'message')\n",
    "\n",
    "with context:\n",
    "    display(test_df_tokens.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:43.792921Z",
     "iopub.status.busy": "2021-10-08T15:32:43.792567Z",
     "iopub.status.idle": "2021-10-08T15:32:43.798219Z",
     "shell.execute_reply": "2021-10-08T15:32:43.79766Z",
     "shell.execute_reply.started": "2021-10-08T15:32:43.792876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function that removes stopwords\n",
    "def stop_words(df, column_name):\n",
    "    df = df.copy()\n",
    "    # Returns tokenized words that are not rt\n",
    "    returns = lambda tweets: [i for i in tweets if i != 'rt']\n",
    "    df[column_name] = df[column_name].apply(returns)\n",
    "    \n",
    "    #Create a function stops which returns the words in a tokenized dataframe that do not appear in a stopwords set\n",
    "    stop_word = lambda tweets: [i for i in tweets if i not in sw('en')]\n",
    "    df[column_name] = df[column_name].apply(stop_word)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:43.799678Z",
     "iopub.status.busy": "2021-10-08T15:32:43.799316Z",
     "iopub.status.idle": "2021-10-08T15:32:56.938975Z",
     "shell.execute_reply": "2021-10-08T15:32:56.938452Z",
     "shell.execute_reply.started": "2021-10-08T15:32:43.79964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the stops function the tokenized testing dataset dataframe\n",
    "train_df_stopwords = stop_words(train_df_tokens, 'message')\n",
    "\n",
    "with context:\n",
    "    display(train_df_stopwords.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:32:56.940322Z",
     "iopub.status.busy": "2021-10-08T15:32:56.939993Z",
     "iopub.status.idle": "2021-10-08T15:33:05.320217Z",
     "shell.execute_reply": "2021-10-08T15:33:05.319319Z",
     "shell.execute_reply.started": "2021-10-08T15:32:56.940266Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df_stopwords = stop_words(test_df_tokens, 'message')\n",
    "\n",
    "with context:\n",
    "    display(test_df_stopwords.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:05.322337Z",
     "iopub.status.busy": "2021-10-08T15:33:05.321773Z",
     "iopub.status.idle": "2021-10-08T15:33:08.151067Z",
     "shell.execute_reply": "2021-10-08T15:33:08.150263Z",
     "shell.execute_reply.started": "2021-10-08T15:33:05.322294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to lemmatize words in training dataframe\n",
    "train_df_lemmatized = train_df_stopwords.copy()\n",
    "\n",
    "train_df_lemmatized['message'] = train_df_lemmatized['message'].apply(lambda sentence : [WordNetLemmatizer().lemmatize(word) for word in sentence])\n",
    "\n",
    "# Display the first 10 rows of the lemmatized_train dataframe, allowing maxmimum width for the message column\n",
    "with context:\n",
    "    display(train_df_lemmatized.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.152935Z",
     "iopub.status.busy": "2021-10-08T15:33:08.152456Z",
     "iopub.status.idle": "2021-10-08T15:33:08.656692Z",
     "shell.execute_reply": "2021-10-08T15:33:08.655825Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.152893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to lemmatize words in training dataframe\n",
    "test_df_lemmatized = test_df_stopwords.copy()\n",
    "\n",
    "test_df_lemmatized['message'] = test_df_lemmatized['message'].apply(lambda sentence : [WordNetLemmatizer().lemmatize(word) for word in sentence])\n",
    "\n",
    "# Display the first 10 rows of the lemmatized_train dataframe, allowing maxmimum width for the message column\n",
    "with context:\n",
    "    display(test_df_lemmatized.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.658628Z",
     "iopub.status.busy": "2021-10-08T15:33:08.658121Z",
     "iopub.status.idle": "2021-10-08T15:33:08.683288Z",
     "shell.execute_reply": "2021-10-08T15:33:08.682462Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.658588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge tokenized words into sentences (train_df_lammetized)\n",
    "train_df_lemmatized['message'] = [' '.join(i) for i in train_df_lemmatized['message'].values]\n",
    "\n",
    "with context:\n",
    "    display(train_df_lemmatized.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.684769Z",
     "iopub.status.busy": "2021-10-08T15:33:08.684543Z",
     "iopub.status.idle": "2021-10-08T15:33:08.707526Z",
     "shell.execute_reply": "2021-10-08T15:33:08.706658Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.684732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge tokenized words into sentences (test_df_lammetized)\n",
    "test_df_lemmatized['message'] = [' '.join(i) for i in test_df_lemmatized['message'].values]\n",
    "\n",
    "with context:\n",
    "    display(test_df_lemmatized.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data (EDA)\n",
    "<a id='EDA'></a>\n",
    "   [Back to table of contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Sentiment Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.709246Z",
     "iopub.status.busy": "2021-10-08T15:33:08.708935Z",
     "iopub.status.idle": "2021-10-08T15:33:08.73729Z",
     "shell.execute_reply": "2021-10-08T15:33:08.736618Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.709206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grouping tweets by sentiment and display count in message column\n",
    "sentiment_df = train_df_lemmatized.groupby('sentiment').count()['message'].reset_index().sort_values(by = 'message', ascending = False)\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Bar Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.738709Z",
     "iopub.status.busy": "2021-10-08T15:33:08.738513Z",
     "iopub.status.idle": "2021-10-08T15:33:08.88578Z",
     "shell.execute_reply": "2021-10-08T15:33:08.884949Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.738685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize number of tweets using a bar plot\n",
    "bar_graph = go.Figure(go.Bar(x = ['Positive', 'News', 'Neutral', 'Negative'],y = sentiment_df['message'], \n",
    "                       marker = {'color': sentiment_df['message'],'colorscale': 'Viridis'})) \n",
    "bar_graph.update_layout(yaxis_title = 'No. of Tweets', xaxis_title = 'Sentiment', title = 'No. of tweets per sentiment')\n",
    "bar_graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cloud Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.887991Z",
     "iopub.status.busy": "2021-10-08T15:33:08.887127Z",
     "iopub.status.idle": "2021-10-08T15:33:08.901069Z",
     "shell.execute_reply": "2021-10-08T15:33:08.90037Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.887956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collecting words from different sentiments\n",
    "pos_words = \" \".join([i for i in train_df_lemmatized['message'][train_df_lemmatized['sentiment'] == 1]])\n",
    "neg_words = \" \".join([y for y in train_df_lemmatized['message'][train_df_lemmatized['sentiment'] == -1]])\n",
    "neutral_words = \" \".join([i for i in train_df_lemmatized['message'][train_df_lemmatized['sentiment'] == 0]])\n",
    "news_words = \" \".join([y for y in train_df_lemmatized['message'][train_df_lemmatized['sentiment'] == 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.902434Z",
     "iopub.status.busy": "2021-10-08T15:33:08.902204Z",
     "iopub.status.idle": "2021-10-08T15:33:08.943055Z",
     "shell.execute_reply": "2021-10-08T15:33:08.942238Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.902408Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of frequent words in wordscloud \n",
    "freq_words = ['warming', 'change', 'climate', 'global']\n",
    "new_pos = \" \".join([i for i in pos_words.split() if i not in freq_words])\n",
    "new_neg = \" \".join([y for y in neg_words.split() if y not in freq_words])\n",
    "new_neutral = \" \".join([i for i in neutral_words.split() if i not in freq_words])\n",
    "new_news = \" \".join([y for y in news_words.split() if y not in freq_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Hashtags Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.94464Z",
     "iopub.status.busy": "2021-10-08T15:33:08.944236Z",
     "iopub.status.idle": "2021-10-08T15:33:08.94919Z",
     "shell.execute_reply": "2021-10-08T15:33:08.948578Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.944562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hash_tags function to extract hashtags\n",
    "def hashtag_function(tweet):\n",
    "    hash_tags = []\n",
    "    for i in tweet: \n",
    "        tags = re.findall(r\"#(\\w+)\", i)\n",
    "        hash_tags.append(tags)\n",
    "    return hash_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:08.950773Z",
     "iopub.status.busy": "2021-10-08T15:33:08.950417Z",
     "iopub.status.idle": "2021-10-08T15:33:09.307766Z",
     "shell.execute_reply": "2021-10-08T15:33:09.307087Z",
     "shell.execute_reply.started": "2021-10-08T15:33:08.950745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extracting hashtags associated to positive, negative, neutral and news class\n",
    "pos_tags = hashtag_function(train['message'][train['sentiment'] == 1])\n",
    "neg_tags = hashtag_function(train['message'][train['sentiment'] == -1])\n",
    "neutral_tags = hashtag_function(train['message'][train['sentiment'] == 0])\n",
    "news_tags = hashtag_function(train['message'][train['sentiment'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.309198Z",
     "iopub.status.busy": "2021-10-08T15:33:09.308848Z",
     "iopub.status.idle": "2021-10-08T15:33:09.35559Z",
     "shell.execute_reply": "2021-10-08T15:33:09.354764Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.309172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list for every sentiment\n",
    "pos_tags = sum(pos_tags, [])\n",
    "neg_tags = sum(neg_tags, [])\n",
    "neutral_tags = sum(neutral_tags, [])\n",
    "news_tags = sum(news_tags, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.357147Z",
     "iopub.status.busy": "2021-10-08T15:33:09.356799Z",
     "iopub.status.idle": "2021-10-08T15:33:09.379633Z",
     "shell.execute_reply": "2021-10-08T15:33:09.37895Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.35712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Displaying the most frequent words in positive, negative, neutral and news hashtags list\n",
    "word_pos = nltk.FreqDist(pos_tags)\n",
    "word_neg = nltk.FreqDist(neg_tags)\n",
    "word_neutral = nltk.FreqDist(neutral_tags)\n",
    "word_news = nltk.FreqDist(news_tags)\n",
    "\n",
    "#Dataframes\n",
    "word_pos_df = pd.DataFrame({'Hashtags' : list(word_pos.keys()),'Count' : list(word_pos.values())})\n",
    "word_neg_df = pd.DataFrame({'Hashtags' : list(word_neg.keys()),'Count' : list(word_neg.values())})\n",
    "word_neutral_df = pd.DataFrame({'Hashtags' : list(word_neutral.keys()),'Count' : list(word_neutral.values())})\n",
    "word_news_df = pd.DataFrame({'Hashtags' : list(word_news.keys()),'Count' : list(word_news.values())})\n",
    "\n",
    "# Sorting in descending order\n",
    "word_pos_df_sorted = word_pos_df.sort_values(by = \"Count\", ascending = False)\n",
    "word_neg_df_sorted = word_neg_df.sort_values(by = \"Count\", ascending = False)\n",
    "word_neutral_df_sorted = word_neutral_df.sort_values(by = \"Count\", ascending = False)\n",
    "word_news_df_sorted = word_news_df.sort_values(by = \"Count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.381123Z",
     "iopub.status.busy": "2021-10-08T15:33:09.380789Z",
     "iopub.status.idle": "2021-10-08T15:33:09.394827Z",
     "shell.execute_reply": "2021-10-08T15:33:09.39398Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.381097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display first 10 rows of most frequent words of positive sentiment\n",
    "word_pos_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.398222Z",
     "iopub.status.busy": "2021-10-08T15:33:09.398007Z",
     "iopub.status.idle": "2021-10-08T15:33:09.408194Z",
     "shell.execute_reply": "2021-10-08T15:33:09.407652Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.398197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display first 10 rows of most frequent words of negative sentiment\n",
    "word_neg_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.409697Z",
     "iopub.status.busy": "2021-10-08T15:33:09.409319Z",
     "iopub.status.idle": "2021-10-08T15:33:09.423868Z",
     "shell.execute_reply": "2021-10-08T15:33:09.42289Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.409669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display first 10 rows of most frequent words of news sentiment\n",
    "word_news_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.426004Z",
     "iopub.status.busy": "2021-10-08T15:33:09.42525Z",
     "iopub.status.idle": "2021-10-08T15:33:09.436236Z",
     "shell.execute_reply": "2021-10-08T15:33:09.435388Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.425959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display first 10 rows of most frequent words of news sentiment\n",
    "word_neutral_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Words extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.438141Z",
     "iopub.status.busy": "2021-10-08T15:33:09.437604Z",
     "iopub.status.idle": "2021-10-08T15:33:09.493438Z",
     "shell.execute_reply": "2021-10-08T15:33:09.492793Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.438101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lambda function for extracting words\n",
    "words_extractor = lambda words:  \" \".join([i for i in words.split() if i not in freq_words])\n",
    "\n",
    "word_pos = train_df_lemmatized[train_df_lemmatized['sentiment'] == 1] \n",
    "word_pos = word_pos['message'].apply(words_extractor)\n",
    "word_neg = train_df_lemmatized[train_df_lemmatized['sentiment'] == -1]\n",
    "word_neg = word_neg['message'].apply(words_extractor)\n",
    "word_neutral = train_df_lemmatized[train_df_lemmatized['sentiment'] == 0]\n",
    "word_neutral = word_neutral['message'].apply(words_extractor)\n",
    "word_news = train_df_lemmatized[train_df_lemmatized['sentiment'] == 2]\n",
    "word_news = word_news['message'].apply(words_extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Call CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.494877Z",
     "iopub.status.busy": "2021-10-08T15:33:09.494347Z",
     "iopub.status.idle": "2021-10-08T15:33:09.735633Z",
     "shell.execute_reply": "2021-10-08T15:33:09.73492Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.494842Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use CountVectorizer to transform word_positive, word_negative, word_neutral and word_news\n",
    "# word_positive\n",
    "countV_pos = CountVectorizer()\n",
    "docs_positive = countV_pos.fit_transform(word_pos)\n",
    "features_positive = countV_pos.get_feature_names()\n",
    "\n",
    "# word_negative\n",
    "countV_neg = CountVectorizer()\n",
    "docs_negative = countV_neg.fit_transform(word_neg)\n",
    "features_negative = countV_neg.get_feature_names()\n",
    "\n",
    "# word_neutral\n",
    "countV_neutral = CountVectorizer()\n",
    "docs_neutral = countV_neutral.fit_transform(word_neutral)\n",
    "features_neutral = countV_neutral.get_feature_names()\n",
    "\n",
    "# word_news\n",
    "countV_news = CountVectorizer()\n",
    "docs_news = countV_news.fit_transform(word_news)\n",
    "features_news = countV_news.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Frequency Distribution Visualizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:09.737239Z",
     "iopub.status.busy": "2021-10-08T15:33:09.736553Z",
     "iopub.status.idle": "2021-10-08T15:33:10.026548Z",
     "shell.execute_reply": "2021-10-08T15:33:10.025654Z",
     "shell.execute_reply.started": "2021-10-08T15:33:09.737209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display frequency distribution of top 10 tokens for positive sentiment'\n",
    "fDist_pos = FreqDistVisualizer(features = features_positive, orient = 'v', n = 10, \n",
    "            color = 'm', title = 'frequency_distribution of top 10 tokens for positive sentiment')\n",
    "visual_pos = RadViz(classes = docs_positive, features = features_positive, size = (800, 420))\n",
    "\n",
    "fDist_pos.fit(docs_positive)\n",
    "fDist_pos.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:10.027935Z",
     "iopub.status.busy": "2021-10-08T15:33:10.027717Z",
     "iopub.status.idle": "2021-10-08T15:33:10.253065Z",
     "shell.execute_reply": "2021-10-08T15:33:10.252295Z",
     "shell.execute_reply.started": "2021-10-08T15:33:10.027909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display frequency distribution of top 10 tokens for negative sentiment'\n",
    "fDist_neg = FreqDistVisualizer(features = features_negative, orient = 'v', n = 10, \n",
    "            color = 'c', title = 'frequency_distribution of top 10 tokens for negative sentiment')\n",
    "visual_neg = RadViz(classes = docs_negative, features = features_negative, size = (800, 420))\n",
    "\n",
    "fDist_neg.fit(docs_negative)\n",
    "fDist_neg.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:10.254392Z",
     "iopub.status.busy": "2021-10-08T15:33:10.25416Z",
     "iopub.status.idle": "2021-10-08T15:33:10.468381Z",
     "shell.execute_reply": "2021-10-08T15:33:10.467638Z",
     "shell.execute_reply.started": "2021-10-08T15:33:10.254358Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display frequency distribution of top 10 tokens for neutral sentiment'\n",
    "fDist_neutral = FreqDistVisualizer(features = features_neutral, orient = 'v', n = 10, \n",
    "            color = 'b', title = 'frequency_distribution of top 10 tokens for negative sentiment')\n",
    "visual_neutral = RadViz(classes = docs_neutral, features = features_neutral, size = (800, 420))\n",
    "\n",
    "fDist_neutral.fit(docs_neutral)\n",
    "fDist_neutral.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:10.469722Z",
     "iopub.status.busy": "2021-10-08T15:33:10.469504Z",
     "iopub.status.idle": "2021-10-08T15:33:10.67196Z",
     "shell.execute_reply": "2021-10-08T15:33:10.671401Z",
     "shell.execute_reply.started": "2021-10-08T15:33:10.469695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display frequency distribution of top 10 tokens for news sentiment\n",
    "fDist_news = FreqDistVisualizer(features = features_news, orient = 'v', n = 10, \n",
    "            color = 'r', title = 'frequency_distribution of top 10 tokens for news sentiment')\n",
    "visual_news = RadViz(classes = docs_news, features = features_news, size = (800, 420))\n",
    "\n",
    "fDist_news.fit(docs_news)\n",
    "fDist_news.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature  Engineering\n",
    "<a id='extraction'></a>\n",
    "   [Back to table of contents](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:46.308999Z",
     "iopub.status.busy": "2021-10-08T15:33:46.308255Z",
     "iopub.status.idle": "2021-10-08T15:33:46.315327Z",
     "shell.execute_reply": "2021-10-08T15:33:46.31443Z",
     "shell.execute_reply.started": "2021-10-08T15:33:46.308958Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(message):\n",
    "    \n",
    "    # set to lower cases\n",
    "    str_msg = message.lower()\n",
    "    str_msg = re.sub(r\"http\\S+\", \"\", str_msg)\n",
    "    \n",
    "    # tokenize string\n",
    "    tokenized_str = TweetTokenizer(strip_handles = True)\n",
    "    str_msg = tokenized_str.tokenize(str_msg)\n",
    "    \n",
    "    # join and extract string.\n",
    "    str_msg = \" \".join(str_msg)\n",
    "    str_msg = re.sub(r'[^a-z0-9\\s]', '', str_msg)\n",
    "    str_msg = re.sub(r'[0-9]+', '', str_msg)\n",
    "    \n",
    "    tweet = re.sub(r'^rt', '', str_msg)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:33:49.615663Z",
     "iopub.status.busy": "2021-10-08T15:33:49.615035Z",
     "iopub.status.idle": "2021-10-08T15:33:52.293043Z",
     "shell.execute_reply": "2021-10-08T15:33:52.29224Z",
     "shell.execute_reply.started": "2021-10-08T15:33:49.615616Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count Vectorizing the train dataset\n",
    "train_df = train.copy()\n",
    "train_df['message']= train_df['message'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:37:09.070365Z",
     "iopub.status.busy": "2021-10-08T15:37:09.070054Z",
     "iopub.status.idle": "2021-10-08T15:37:09.075457Z",
     "shell.execute_reply": "2021-10-08T15:37:09.074451Z",
     "shell.execute_reply.started": "2021-10-08T15:37:09.070335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declare variable x and y\n",
    "x = train_df['message']\n",
    "y = train_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:43:07.098854Z",
     "iopub.status.busy": "2021-10-08T15:43:07.097998Z",
     "iopub.status.idle": "2021-10-08T15:43:08.109459Z",
     "shell.execute_reply": "2021-10-08T15:43:08.108625Z",
     "shell.execute_reply.started": "2021-10-08T15:43:07.098812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call CountVectorizer \n",
    "count_vector = CountVectorizer(ngram_range =(1,2))\n",
    "X = count_vector.fit_transform(x)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T15:46:41.919004Z",
     "iopub.status.busy": "2021-10-08T15:46:41.918669Z",
     "iopub.status.idle": "2021-10-08T15:46:41.93157Z",
     "shell.execute_reply": "2021-10-08T15:46:41.930841Z",
     "shell.execute_reply.started": "2021-10-08T15:46:41.918967Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelling\n",
    "<a id='modelling'></a>\n",
    "   [Back to table of contents](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  **Logistic Regression Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T16:16:40.721974Z",
     "iopub.status.busy": "2021-10-08T16:16:40.721108Z",
     "iopub.status.idle": "2021-10-08T16:16:42.840399Z",
     "shell.execute_reply": "2021-10-08T16:16:42.839322Z",
     "shell.execute_reply.started": "2021-10-08T16:16:40.721899Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declare logistic Regression Classifier \n",
    "Log_reg_class = LogisticRegression(multi_class = 'ovr', solver = 'liblinear', \n",
    "                                   random_state = 42).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T16:06:12.430102Z",
     "iopub.status.busy": "2021-10-08T16:06:12.429823Z",
     "iopub.status.idle": "2021-10-08T16:06:12.439489Z",
     "shell.execute_reply": "2021-10-08T16:06:12.438718Z",
     "shell.execute_reply.started": "2021-10-08T16:06:12.430075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the predictions\n",
    "pred_log_reg = Log_reg_class.predict(X_test)\n",
    "pred_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T16:10:54.970962Z",
     "iopub.status.busy": "2021-10-08T16:10:54.970644Z",
     "iopub.status.idle": "2021-10-08T16:10:54.982056Z",
     "shell.execute_reply": "2021-10-08T16:10:54.981077Z",
     "shell.execute_reply.started": "2021-10-08T16:10:54.97093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking model performance with F1 score\n",
    "acc_model = f1_score(y_test,pred_log_reg,average =\"weighted\") \n",
    "acc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Support Vector Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T17:01:19.328806Z",
     "iopub.status.busy": "2021-10-08T17:01:19.328438Z",
     "iopub.status.idle": "2021-10-08T17:02:11.828603Z",
     "shell.execute_reply": "2021-10-08T17:02:11.827679Z",
     "shell.execute_reply.started": "2021-10-08T17:01:19.328769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declare support vector classifier model\n",
    "Supp_Vect_Class = SVC(C = 10, gamma = 0.01).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T17:02:11.830989Z",
     "iopub.status.busy": "2021-10-08T17:02:11.830585Z",
     "iopub.status.idle": "2021-10-08T17:02:18.721453Z",
     "shell.execute_reply": "2021-10-08T17:02:18.720858Z",
     "shell.execute_reply.started": "2021-10-08T17:02:11.830943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the predictions\n",
    "pred_supp_vect = Supp_Vect_Class.predict(X_test)\n",
    "pred_supp_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T17:02:18.723065Z",
     "iopub.status.busy": "2021-10-08T17:02:18.722385Z",
     "iopub.status.idle": "2021-10-08T17:02:18.731227Z",
     "shell.execute_reply": "2021-10-08T17:02:18.730443Z",
     "shell.execute_reply.started": "2021-10-08T17:02:18.723034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking model performance with F1 score\n",
    "acc_model2 = f1_score(y_test,pred_supp_vect,average =\"weighted\") \n",
    "acc_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **SMOTE Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T16:52:07.036727Z",
     "iopub.status.busy": "2021-10-08T16:52:07.036424Z",
     "iopub.status.idle": "2021-10-08T16:52:07.062506Z",
     "shell.execute_reply": "2021-10-08T16:52:07.06173Z",
     "shell.execute_reply.started": "2021-10-08T16:52:07.036698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declare SMOTE Naive Bayes Classifier\n",
    "Naive_Bayes_Class = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T16:54:30.038798Z",
     "iopub.status.busy": "2021-10-08T16:54:30.038522Z",
     "iopub.status.idle": "2021-10-08T16:54:30.047648Z",
     "shell.execute_reply": "2021-10-08T16:54:30.046585Z",
     "shell.execute_reply.started": "2021-10-08T16:54:30.038771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the predictions\n",
    "pred_naive_bayes = Naive_Bayes_Class.predict(X_test)\n",
    "pred_naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T16:55:56.308647Z",
     "iopub.status.busy": "2021-10-08T16:55:56.306915Z",
     "iopub.status.idle": "2021-10-08T16:55:56.321419Z",
     "shell.execute_reply": "2021-10-08T16:55:56.32056Z",
     "shell.execute_reply.started": "2021-10-08T16:55:56.308586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking model performance with F1 score\n",
    "acc_model3 = f1_score(y_test,pred_log_reg,average =\"weighted\") \n",
    "acc_model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifier model is performing better than others.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T18:00:23.953636Z",
     "iopub.status.busy": "2021-10-08T18:00:23.953008Z",
     "iopub.status.idle": "2021-10-08T18:00:26.177926Z",
     "shell.execute_reply": "2021-10-08T18:00:26.177142Z",
     "shell.execute_reply.started": "2021-10-08T18:00:23.953592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model test data \n",
    "test_df = test.copy()\n",
    "test_df['message'] = test_df['message'].apply(preprocessing)\n",
    "test_count_vector =  count_vector.transform(test_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T18:05:44.453567Z",
     "iopub.status.busy": "2021-10-08T18:05:44.453051Z",
     "iopub.status.idle": "2021-10-08T18:06:06.68508Z",
     "shell.execute_reply": "2021-10-08T18:06:06.684449Z",
     "shell.execute_reply.started": "2021-10-08T18:05:44.453527Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on test_data\n",
    "pred_supp_vect_sub = Supp_Vect_Class.predict(test_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T18:09:14.511683Z",
     "iopub.status.busy": "2021-10-08T18:09:14.510592Z",
     "iopub.status.idle": "2021-10-08T18:09:14.534865Z",
     "shell.execute_reply": "2021-10-08T18:09:14.53392Z",
     "shell.execute_reply.started": "2021-10-08T18:09:14.511626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the submission dataframe\n",
    "submission = pd.DataFrame({'tweetid' : test_df['tweetid'], \n",
    "                           'sentiment' : pred_supp_vect_sub})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T18:24:59.137326Z",
     "iopub.status.busy": "2021-10-08T18:24:59.136615Z",
     "iopub.status.idle": "2021-10-08T18:24:59.172713Z",
     "shell.execute_reply": "2021-10-08T18:24:59.171758Z",
     "shell.execute_reply.started": "2021-10-08T18:24:59.137281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save submision file on csv.\n",
    "submission.to_csv(\"Bote_Mkwanazi_Classification_Prediction.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
